{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RLHF WordPress Memory Trainer sur Google Colab\n",
    "\n",
    "Ce notebook permet d'exécuter le trainer RLHF de DeepSeek sur Google Colab avec accélération GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation des dépendances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cloner le dépôt\n",
    "!git clone https://github.com/pascalseppey/renee.git\n",
    "%cd renee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installer les dépendances nécessaires\n",
    "!pip install openai requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration de l'environnement Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer les répertoires nécessaires\n",
    "!mkdir -p ./data/memory\n",
    "!mkdir -p ./checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration pour utiliser PyTorch avec GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier si le GPU est disponible\n",
    "import torch\n",
    "print(f\"GPU disponible: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Nom du GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Mémoire totale: {torch.cuda.get_device_properties(0).total_memory / 1e9} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparer les clés API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurer la clé API OpenAI\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "# Remplacez par votre clé API si nécessaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation d'Ollama pour exécuter DeepSeek localement\n",
    "\n",
    "Étant donné que Google Colab est un environnement Linux, nous pouvons installer Ollama directement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installer Ollama pour Linux\n",
    "!curl -fsSL https://ollama.com/install.sh | sh\n",
    "# Démarrer le service Ollama en arrière-plan\n",
    "!ollama serve &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Télécharger le modèle DeepSeek\n",
    "!ollama pull deepseek:7b-chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exécution de l'entraînement RLHF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapter le script pour Google Colab\n",
    "!python rlhf_wordpress_memory_trainer.py --num_examples 30 --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vérification de la mémoire hiérarchique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier le contenu du fichier de mémoire hiérarchique\n",
    "import json\n",
    "\n",
    "memory_file = './debug_memory/hierarchical_memory.json'\n",
    "if os.path.exists(memory_file):\n",
    "    with open(memory_file, 'r') as f:\n",
    "        memory_data = json.load(f)\n",
    "\n",
    "    # Afficher les statistiques\n",
    "    print(\"Statistiques de la mémoire:\")\n",
    "    for level, memories in memory_data[\"memory_levels\"].items():\n",
    "        print(f\"  {level}: {len(memories)} entrées\")\n",
    "    print(f\"Total: {sum(len(memories) for level, memories in memory_data['memory_levels'].items())} entrées\")\n",
    "    \n",
    "    # Afficher quelques exemples de mémoire de niveau FACTUAL\n",
    "    if memory_data[\"memory_levels\"][\"FACTUAL\"]:\n",
    "        print(\"\\nExemples de mémoire FACTUAL:\")\n",
    "        for i, memory in enumerate(memory_data[\"memory_levels\"][\"FACTUAL\"][:3]):\n",
    "            print(f\"\\nMémoire #{i+1} (ID: {memory['id']})\")\n",
    "            print(f\"Contenu: {memory['content'][:200]}...\")\n",
    "            print(f\"Importance: {memory['importance']}\")\n",
    "            print(f\"Score: {memory['metadata'].get('score', 'N/A')}\")\n",
    "else:\n",
    "    print(f\"Fichier de mémoire {memory_file} non trouvé\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement continu et amélioration du modèle\n",
    "\n",
    "Vous pouvez exécuter plusieurs itérations d'entraînement pour améliorer continuellement le modèle. Entre chaque itération, le système sauvegardera automatiquement les nouvelles connaissances acquises dans le fichier de mémoire hiérarchique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécuter plusieurs itérations d'entraînement\n",
    "for i in range(3):\n",
    "    print(f\"\\n*** Itération d'entraînement #{i+1} ***\\n\")\n",
    "    !python rlhf_wordpress_memory_trainer.py --num_examples 10 --verbose"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
